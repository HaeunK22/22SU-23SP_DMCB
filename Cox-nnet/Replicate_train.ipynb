{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Code_manual import Coxnnet, PartialNLL\n",
    "from lifelines.utils import concordance_index\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Survival Analysis\\\\Cox-nnet'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load KIRC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_data = pd.read_table(\"./KIRC_expr.tsv\", header=None)\n",
    "\n",
    "time_data = pd.read_table(\"./KIRC_time.tsv\", header=None)\n",
    "\n",
    "observed_data = pd.read_table(\"./KIRC_event.tsv\", header=None)\n",
    "\n",
    "map_dict = {'DECEASED' : 1,\n",
    "            'LIVING' : 0}\n",
    "observed_data = observed_data[0].apply(lambda x : map_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(np.array(expr_data), dtype=torch.float)\n",
    "time = torch.tensor(time_data.to_numpy(), dtype=torch.long)\n",
    "observed = torch.tensor(observed_data.to_numpy(), dtype=torch.float)\n",
    "\n",
    "train_idx, test_idx, _, _ = train_test_split(np.arange(X.shape[0]), observed, test_size=0.3, random_state=42)\n",
    "\n",
    "train_X = X[train_idx,:]\n",
    "test_X = X[test_idx,:]\n",
    "\n",
    "train_time = time[train_idx]\n",
    "test_time = time[test_idx]\n",
    "\n",
    "train_observed = observed[train_idx]\n",
    "test_observed = observed[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "if cuda:\n",
    "    device = torch.device(f'cuda:{0}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = torch.tensor(train_X, device=device)\n",
    "        self.time_data = torch.tensor(train_time, device=device)\n",
    "        self.observed_data = torch.tensor(train_observed, device=device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(self.x_data[index]).clone().detach()\n",
    "        time = torch.tensor(self.time_data[index]).clone().detach()\n",
    "        observed = torch.tensor(self.observed_data[index]).clone().detach()\n",
    "        return x, time, observed\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = torch.tensor(test_X, device=device)\n",
    "        self.time_data = torch.tensor(test_time, device=device)\n",
    "        self.observed_data = torch.tensor(test_observed, device=device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(self.x_data[index]).clone().detach()\n",
    "        time = torch.tensor(self.time_data[index]).clone().detach()\n",
    "        observed = torch.tensor(self.observed_data[index]).clone().detach()\n",
    "        return x, time, observed\n",
    "    \n",
    "training_data = TrainDataset()\n",
    "test_data = TestDataset()\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size = training_data.__len__())\n",
    "test_dataloader = DataLoader(test_data, batch_size = test_data.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "\n",
    "hidden_dim = 500\n",
    "model = Coxnnet(train_X.shape[1], hidden_dim)\n",
    "model = model.to(device)\n",
    "learning_rate = 5e-5\n",
    "epochs = 137\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = PartialNLL()\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, t):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, time, observed) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, time, observed)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()   # bc/ gradients by default add up; to prevent double counting.\n",
    "        loss.backward() # deposits gradients\n",
    "        optimizer.step()    # adjust parameters with gradients\n",
    "        \n",
    "        train_perf = 0\n",
    "        train_perf = concordance_index(event_times = time.cpu().detach().numpy(),\n",
    "                                       event_observed = observed.cpu().detach().numpy(),\n",
    "                                       predicted_scores = -pred.cpu().detach().numpy())    \n",
    "        \n",
    "        if ((t+1) % 25 == 0):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            print(f\"Train Accuracy: {train_perf}\\n\")\n",
    "            print(f\"Train Loss: {loss.item()}\\n\")\n",
    "\n",
    "# iterate over test dataset to check model performance\n",
    "def test_loop(dataloader, model, t):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_perf = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, time, observed in dataloader:\n",
    "            pred = model.forward(X)\n",
    "            test_perf = concordance_index(event_times = time.cpu().detach().numpy(),\n",
    "                                          event_observed = observed.cpu().detach().numpy(),\n",
    "                                          predicted_scores = -pred.cpu().detach().numpy())\n",
    "\n",
    "    if ((t+1) % 25 == 0):\n",
    "        print(f\"Test Accuracy: {test_perf}\\n\")\n",
    "        \n",
    "    if (t+1 == epochs):\n",
    "        acc.append(test_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Replicate 1\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7066998548019083\n",
      "\n",
      "Train Loss: 5.123104102662653\n",
      "\n",
      "Test Accuracy: 0.6135759558372521\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7314872433105165\n",
      "\n",
      "Train Loss: 5.059924014599616\n",
      "\n",
      "Test Accuracy: 0.6370885299529748\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7894973380349858\n",
      "\n",
      "Train Loss: 4.83430856379\n",
      "\n",
      "Test Accuracy: 0.6377019014516458\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7942681324759732\n",
      "\n",
      "Train Loss: 4.827643644500971\n",
      "\n",
      "Test Accuracy: 0.6469024739317113\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8162552720735671\n",
      "\n",
      "Train Loss: 4.846830905730161\n",
      "\n",
      "Test Accuracy: 0.6399509302801063\n",
      "\n",
      "------------\n",
      "Replicate 2\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7144783239991703\n",
      "\n",
      "Train Loss: 5.086173087410247\n",
      "\n",
      "Test Accuracy: 0.6571253322428952\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7769480743967365\n",
      "\n",
      "Train Loss: 4.8845963055409785\n",
      "\n",
      "Test Accuracy: 0.6366796156205276\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7641568139390168\n",
      "\n",
      "Train Loss: 4.9180772490237645\n",
      "\n",
      "Test Accuracy: 0.6669392762216315\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8003526239369425\n",
      "\n",
      "Train Loss: 4.805727472607261\n",
      "\n",
      "Test Accuracy: 0.6520139030873032\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7848993984650487\n",
      "\n",
      "Train Loss: 4.822337937005466\n",
      "\n",
      "Test Accuracy: 0.6724596197096708\n",
      "\n",
      "------------\n",
      "Replicate 3\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7111249395007951\n",
      "\n",
      "Train Loss: 5.127520071044264\n",
      "\n",
      "Test Accuracy: 0.6045798405234103\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7394385673788287\n",
      "\n",
      "Train Loss: 5.0008501073603355\n",
      "\n",
      "Test Accuracy: 0.6213453281537518\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.775323238608864\n",
      "\n",
      "Train Loss: 4.903678822540795\n",
      "\n",
      "Test Accuracy: 0.6362707012880802\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7804397427919518\n",
      "\n",
      "Train Loss: 4.8152554271518335\n",
      "\n",
      "Test Accuracy: 0.6432222449396852\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7954089746249049\n",
      "\n",
      "Train Loss: 4.7799141613565\n",
      "\n",
      "Test Accuracy: 0.6309548149662646\n",
      "\n",
      "------------\n",
      "Replicate 4\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.696051994745212\n",
      "\n",
      "Train Loss: 5.144557031993454\n",
      "\n",
      "Test Accuracy: 0.6450623594356982\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7401299868630298\n",
      "\n",
      "Train Loss: 5.028858574905962\n",
      "\n",
      "Test Accuracy: 0.6595788182375792\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7651248012168983\n",
      "\n",
      "Train Loss: 4.887362495314385\n",
      "\n",
      "Test Accuracy: 0.6565119607442241\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7744935352278227\n",
      "\n",
      "Train Loss: 4.934764786022407\n",
      "\n",
      "Test Accuracy: 0.6601921897362503\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8080273802115744\n",
      "\n",
      "Train Loss: 4.753521096419485\n",
      "\n",
      "Test Accuracy: 0.6695972193825394\n",
      "\n",
      "------------\n",
      "Replicate 5\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7010647860056697\n",
      "\n",
      "Train Loss: 5.11484952712256\n",
      "\n",
      "Test Accuracy: 0.6454712737681456\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7226370739127429\n",
      "\n",
      "Train Loss: 5.040784528676372\n",
      "\n",
      "Test Accuracy: 0.6440400736045798\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7452119200719076\n",
      "\n",
      "Train Loss: 4.988871781757977\n",
      "\n",
      "Test Accuracy: 0.6753220200368023\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.762359123280094\n",
      "\n",
      "Train Loss: 4.970433796907304\n",
      "\n",
      "Test Accuracy: 0.677366591699039\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7815460139666736\n",
      "\n",
      "Train Loss: 4.834418641962726\n",
      "\n",
      "Test Accuracy: 0.6638724187282764\n",
      "\n",
      "------------\n",
      "Replicate 6\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7341492083246905\n",
      "\n",
      "Train Loss: 5.0519705282811005\n",
      "\n",
      "Test Accuracy: 0.6528317317521979\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7639839590679666\n",
      "\n",
      "Train Loss: 4.927135790032455\n",
      "\n",
      "Test Accuracy: 0.6458801881005929\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7626702620479845\n",
      "\n",
      "Train Loss: 4.942301927437882\n",
      "\n",
      "Test Accuracy: 0.6344305867920671\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.809099080412086\n",
      "\n",
      "Train Loss: 4.811969279472125\n",
      "\n",
      "Test Accuracy: 0.6387241872827643\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7601811519048607\n",
      "\n",
      "Train Loss: 4.9287429280276545\n",
      "\n",
      "Test Accuracy: 0.6493559599263954\n",
      "\n",
      "------------\n",
      "Replicate 7\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7171057180391344\n",
      "\n",
      "Train Loss: 5.061551525736835\n",
      "\n",
      "Test Accuracy: 0.6280924146391331\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7685127566894835\n",
      "\n",
      "Train Loss: 4.958616545657214\n",
      "\n",
      "Test Accuracy: 0.6444489879370272\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7794026135656503\n",
      "\n",
      "Train Loss: 4.903578464429545\n",
      "\n",
      "Test Accuracy: 0.6389286444489879\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8192629468298417\n",
      "\n",
      "Train Loss: 4.690465366853196\n",
      "\n",
      "Test Accuracy: 0.6352484154569618\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8131784553688723\n",
      "\n",
      "Train Loss: 4.750502736413232\n",
      "\n",
      "Test Accuracy: 0.655285217746882\n",
      "\n",
      "------------\n",
      "Replicate 8\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.738989144714098\n",
      "\n",
      "Train Loss: 5.043417425897878\n",
      "\n",
      "Test Accuracy: 0.6244121856471069\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7464219041692595\n",
      "\n",
      "Train Loss: 5.012207889350301\n",
      "\n",
      "Test Accuracy: 0.6407687589450011\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7900504736223467\n",
      "\n",
      "Train Loss: 4.846332915807103\n",
      "\n",
      "Test Accuracy: 0.6693927622163157\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7955472585217451\n",
      "\n",
      "Train Loss: 4.79702364404984\n",
      "\n",
      "Test Accuracy: 0.6759353915354733\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7981746525617092\n",
      "\n",
      "Train Loss: 4.79038065235146\n",
      "\n",
      "Test Accuracy: 0.647720302596606\n",
      "\n",
      "------------\n",
      "Replicate 9\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7238470580100947\n",
      "\n",
      "Train Loss: 5.037988601600078\n",
      "\n",
      "Test Accuracy: 0.6217542424861991\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7316255272073567\n",
      "\n",
      "Train Loss: 5.0103065327899055\n",
      "\n",
      "Test Accuracy: 0.6313637292987119\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7718661411878587\n",
      "\n",
      "Train Loss: 4.89258119389994\n",
      "\n",
      "Test Accuracy: 0.6464935595992639\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7838968402129572\n",
      "\n",
      "Train Loss: 4.85817176350956\n",
      "\n",
      "Test Accuracy: 0.6352484154569618\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7703104473484063\n",
      "\n",
      "Train Loss: 4.86710303747867\n",
      "\n",
      "Test Accuracy: 0.6530361889184216\n",
      "\n",
      "------------\n",
      "Replicate 10\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7040724607619443\n",
      "\n",
      "Train Loss: 5.087786966276852\n",
      "\n",
      "Test Accuracy: 0.6150071560008178\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.733146650072599\n",
      "\n",
      "Train Loss: 4.99619951515492\n",
      "\n",
      "Test Accuracy: 0.6542629319157637\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7581760354006776\n",
      "\n",
      "Train Loss: 4.923642274699406\n",
      "\n",
      "Test Accuracy: 0.6544673890819873\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7747701030215032\n",
      "\n",
      "Train Loss: 4.891512826945433\n",
      "\n",
      "Test Accuracy: 0.6558985892455531\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7965152457996266\n",
      "\n",
      "Train Loss: 4.791717463790834\n",
      "\n",
      "Test Accuracy: 0.661623389899816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"------------\\nReplicate {i+1}\\n------------\")\n",
    "    train_idx, test_idx, _, _ = train_test_split(np.arange(X.shape[0]), observed, test_size=0.3, random_state=i)\n",
    "\n",
    "    train_X = X[train_idx,:]\n",
    "    test_X = X[test_idx,:]\n",
    "\n",
    "    train_time = time[train_idx]\n",
    "    test_time = time[test_idx]\n",
    "\n",
    "    train_observed = observed[train_idx]\n",
    "    test_observed = observed[test_idx]\n",
    "    model = Coxnnet(train_X.shape[1], hidden_dim)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        model.train()\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, t)\n",
    "        model.eval()\n",
    "        test_loop(test_dataloader, model, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: [0.6509916172561848, 0.6610100184011449, 0.6342261296258433, 0.6659169903905132, 0.6603966469024739, 0.6421999591085668, 0.6522183602535269, 0.6601921897362503, 0.6554896749131057, 0.6550807605806583]\n",
      "average of acc: 0.6537722347168268\n"
     ]
    }
   ],
   "source": [
    "print(f\"acc: {acc}\")\n",
    "print(f\"average of acc: {sum(acc)/len(acc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "KIRC_acc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load LAML data & train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_data = pd.read_table(\"./LAML_expr.tsv\", header=None)\n",
    "\n",
    "time_data = pd.read_table(\"./LAML_time.tsv\", header=None)\n",
    "\n",
    "observed_data = pd.read_table(\"./LAML_event.tsv\", header=None)\n",
    "\n",
    "map_dict = {'DECEASED' : 1,\n",
    "            'LIVING' : 0}\n",
    "observed_data = observed_data[0].apply(lambda x : map_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Replicate 1\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7393694254304086\n",
      "\n",
      "Train Loss: 5.000588557581994\n",
      "\n",
      "Test Accuracy: 0.6190962993252913\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7861785245108207\n",
      "\n",
      "Train Loss: 4.86554767563081\n",
      "\n",
      "Test Accuracy: 0.6370885299529748\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7976215169743484\n",
      "\n",
      "Train Loss: 4.84789568848631\n",
      "\n",
      "Test Accuracy: 0.6413821304436721\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.788978773421835\n",
      "\n",
      "Train Loss: 4.860504742863773\n",
      "\n",
      "Test Accuracy: 0.6340216724596197\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.801942888750605\n",
      "\n",
      "Train Loss: 4.784875603853581\n",
      "\n",
      "Test Accuracy: 0.6558985892455531\n",
      "\n",
      "------------\n",
      "Replicate 2\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.6949457235704902\n",
      "\n",
      "Train Loss: 5.1433403482867535\n",
      "\n",
      "Test Accuracy: 0.5673686362707013\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7468367558597802\n",
      "\n",
      "Train Loss: 4.946802048804853\n",
      "\n",
      "Test Accuracy: 0.6139848701696995\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7366037474936044\n",
      "\n",
      "Train Loss: 4.981788551298048\n",
      "\n",
      "Test Accuracy: 0.6370885299529748\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7540620894696812\n",
      "\n",
      "Train Loss: 4.921783279068616\n",
      "\n",
      "Test Accuracy: 0.6491515027601718\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8131784553688723\n",
      "\n",
      "Train Loss: 4.749204279788006\n",
      "\n",
      "Test Accuracy: 0.6440400736045798\n",
      "\n",
      "------------\n",
      "Replicate 3\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.6677037958929682\n",
      "\n",
      "Train Loss: 5.1806246230831645\n",
      "\n",
      "Test Accuracy: 0.6603966469024739\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7417202516766922\n",
      "\n",
      "Train Loss: 5.002852305783665\n",
      "\n",
      "Test Accuracy: 0.6489470455939481\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7930235774044112\n",
      "\n",
      "Train Loss: 4.831276621357343\n",
      "\n",
      "Test Accuracy: 0.6665303618891842\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7891516282928853\n",
      "\n",
      "Train Loss: 4.79599774666286\n",
      "\n",
      "Test Accuracy: 0.6624412185647107\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8088916545668257\n",
      "\n",
      "Train Loss: 4.715160925677255\n",
      "\n",
      "Test Accuracy: 0.669188305050092\n",
      "\n",
      "------------\n",
      "Replicate 4\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.6837101569522229\n",
      "\n",
      "Train Loss: 5.140449908786786\n",
      "\n",
      "Test Accuracy: 0.6358617869556328\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7594897324206596\n",
      "\n",
      "Train Loss: 4.918729976958524\n",
      "\n",
      "Test Accuracy: 0.64015538744633\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.746076194427159\n",
      "\n",
      "Train Loss: 4.973765549658336\n",
      "\n",
      "Test Accuracy: 0.64015538744633\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7980363686648689\n",
      "\n",
      "Train Loss: 4.774210038516793\n",
      "\n",
      "Test Accuracy: 0.6491515027601718\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8100324967157575\n",
      "\n",
      "Train Loss: 4.762930258689772\n",
      "\n",
      "Test Accuracy: 0.6491515027601718\n",
      "\n",
      "------------\n",
      "Replicate 5\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.6670123764087672\n",
      "\n",
      "Train Loss: 5.238288741104389\n",
      "\n",
      "Test Accuracy: 0.589654467389082\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7374680218488557\n",
      "\n",
      "Train Loss: 4.9786726124253855\n",
      "\n",
      "Test Accuracy: 0.6272745859742384\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7782963423909286\n",
      "\n",
      "Train Loss: 4.892341575808705\n",
      "\n",
      "Test Accuracy: 0.6426088734410141\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8076470994952638\n",
      "\n",
      "Train Loss: 4.79266710164125\n",
      "\n",
      "Test Accuracy: 0.6346350439582907\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8214063472308649\n",
      "\n",
      "Train Loss: 4.726977632530684\n",
      "\n",
      "Test Accuracy: 0.6311592721324882\n",
      "\n",
      "------------\n",
      "Replicate 6\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7236050611906244\n",
      "\n",
      "Train Loss: 5.017022203477019\n",
      "\n",
      "Test Accuracy: 0.6303414434675936\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7528175343981194\n",
      "\n",
      "Train Loss: 4.949865388065461\n",
      "\n",
      "Test Accuracy: 0.6530361889184216\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7706215861162967\n",
      "\n",
      "Train Loss: 4.894980997729049\n",
      "\n",
      "Test Accuracy: 0.6673481905540789\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7992809237364309\n",
      "\n",
      "Train Loss: 4.792746531381353\n",
      "\n",
      "Test Accuracy: 0.6747086485381313\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8196086565719422\n",
      "\n",
      "Train Loss: 4.70242796827013\n",
      "\n",
      "Test Accuracy: 0.6771621345328154\n",
      "\n",
      "------------\n",
      "Replicate 7\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.6647652630851137\n",
      "\n",
      "Train Loss: 5.1883856649908155\n",
      "\n",
      "Test Accuracy: 0.6184829278266203\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7343220631957409\n",
      "\n",
      "Train Loss: 4.984010138604369\n",
      "\n",
      "Test Accuracy: 0.6348395011245144\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7906381801839176\n",
      "\n",
      "Train Loss: 4.936537616731162\n",
      "\n",
      "Test Accuracy: 0.6464935595992639\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7890133443960451\n",
      "\n",
      "Train Loss: 4.82954212810392\n",
      "\n",
      "Test Accuracy: 0.6556941320793294\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7688930374057941\n",
      "\n",
      "Train Loss: 4.889872132497155\n",
      "\n",
      "Test Accuracy: 0.6587609895726845\n",
      "\n",
      "------------\n",
      "Replicate 8\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7035884671230035\n",
      "\n",
      "Train Loss: 5.088104421560653\n",
      "\n",
      "Test Accuracy: 0.6456757309343693\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7529212473207495\n",
      "\n",
      "Train Loss: 4.992723948143329\n",
      "\n",
      "Test Accuracy: 0.6428133306072378\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7562054898707046\n",
      "\n",
      "Train Loss: 4.96020699528509\n",
      "\n",
      "Test Accuracy: 0.669188305050092\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7984857913295996\n",
      "\n",
      "Train Loss: 4.801580641890957\n",
      "\n",
      "Test Accuracy: 0.6595788182375792\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7957892553412155\n",
      "\n",
      "Train Loss: 4.809086245727233\n",
      "\n",
      "Test Accuracy: 0.6683704763851973\n",
      "\n",
      "------------\n",
      "Replicate 9\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.6786973656917652\n",
      "\n",
      "Train Loss: 5.17630315538583\n",
      "\n",
      "Test Accuracy: 0.6489470455939481\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7245384774942958\n",
      "\n",
      "Train Loss: 4.980263249073467\n",
      "\n",
      "Test Accuracy: 0.6624412185647107\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7529903892691696\n",
      "\n",
      "Train Loss: 4.9719100462760855\n",
      "\n",
      "Test Accuracy: 0.6738908198732365\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7972412362580378\n",
      "\n",
      "Train Loss: 4.850519544277182\n",
      "\n",
      "Test Accuracy: 0.6687793907176447\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8053999861716103\n",
      "\n",
      "Train Loss: 4.795504928499982\n",
      "\n",
      "Test Accuracy: 0.6851359640155388\n",
      "\n",
      "------------\n",
      "Replicate 10\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.6982299661204453\n",
      "\n",
      "Train Loss: 5.118290389907613\n",
      "\n",
      "Test Accuracy: 0.6313637292987119\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7505358501002558\n",
      "\n",
      "Train Loss: 4.994349215375878\n",
      "\n",
      "Test Accuracy: 0.6260478429768963\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7495332918481643\n",
      "\n",
      "Train Loss: 4.955523768683883\n",
      "\n",
      "Test Accuracy: 0.6452668166019219\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.766853349927401\n",
      "\n",
      "Train Loss: 4.915333603333674\n",
      "\n",
      "Test Accuracy: 0.6456757309343693\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7853142501555694\n",
      "\n",
      "Train Loss: 4.832319039719986\n",
      "\n",
      "Test Accuracy: 0.6495604170926191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"------------\\nReplicate {i+1}\\n------------\")\n",
    "    train_idx, test_idx, _, _ = train_test_split(np.arange(X.shape[0]), observed, test_size=0.3, random_state=i)\n",
    "\n",
    "    train_X = X[train_idx,:]\n",
    "    test_X = X[test_idx,:]\n",
    "\n",
    "    train_time = time[train_idx]\n",
    "    test_time = time[test_idx]\n",
    "\n",
    "    train_observed = observed[train_idx]\n",
    "    test_observed = observed[test_idx]\n",
    "    model = Coxnnet(train_X.shape[1], hidden_dim)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        model.train()\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, t)\n",
    "        model.eval()\n",
    "        test_loop(test_dataloader, model, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAML_acc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PAAD data & train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_data = pd.read_table(\"./PAAD_expr.tsv\", header=None)\n",
    "\n",
    "time_data = pd.read_table(\"./PAAD_time.tsv\", header=None)\n",
    "\n",
    "observed_data = pd.read_table(\"./PAAD_event.tsv\", header=None)\n",
    "\n",
    "map_dict = {'DECEASED' : 1,\n",
    "            'LIVING' : 0}\n",
    "observed_data = observed_data[0].apply(lambda x : map_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Replicate 1\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.6654912535435249\n",
      "\n",
      "Train Loss: 5.204111841234255\n",
      "\n",
      "Test Accuracy: 0.6370885299529748\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7365691765193944\n",
      "\n",
      "Train Loss: 5.095965579928198\n",
      "\n",
      "Test Accuracy: 0.6493559599263954\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7725921316462698\n",
      "\n",
      "Train Loss: 4.8960795436273115\n",
      "\n",
      "Test Accuracy: 0.6469024739317113\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7553066445412432\n",
      "\n",
      "Train Loss: 4.913933476345916\n",
      "\n",
      "Test Accuracy: 0.6520139030873032\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7924012998686303\n",
      "\n",
      "Train Loss: 4.8185248952982\n",
      "\n",
      "Test Accuracy: 0.6661214475567369\n",
      "\n",
      "------------\n",
      "Replicate 2\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7251953260042868\n",
      "\n",
      "Train Loss: 5.107308285012397\n",
      "\n",
      "Test Accuracy: 0.6342261296258433\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7728341284657402\n",
      "\n",
      "Train Loss: 4.914716383640866\n",
      "\n",
      "Test Accuracy: 0.6385197301165406\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7665422111595105\n",
      "\n",
      "Train Loss: 4.864443166031872\n",
      "\n",
      "Test Accuracy: 0.6462891024330403\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8098596418447072\n",
      "\n",
      "Train Loss: 4.788322526045605\n",
      "\n",
      "Test Accuracy: 0.6554896749131057\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7958583972896356\n",
      "\n",
      "Train Loss: 4.7775997874540295\n",
      "\n",
      "Test Accuracy: 0.655285217746882\n",
      "\n",
      "------------\n",
      "Replicate 3\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.6962248496162622\n",
      "\n",
      "Train Loss: 5.196494759479349\n",
      "\n",
      "Test Accuracy: 0.5872009813943979\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7695153149415751\n",
      "\n",
      "Train Loss: 4.9498486196094715\n",
      "\n",
      "Test Accuracy: 0.6313637292987119\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7556869252575538\n",
      "\n",
      "Train Loss: 4.946584106004367\n",
      "\n",
      "Test Accuracy: 0.6287057861378041\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7842425499550577\n",
      "\n",
      "Train Loss: 4.883040572759595\n",
      "\n",
      "Test Accuracy: 0.6344305867920671\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8035677245384775\n",
      "\n",
      "Train Loss: 4.772322775493637\n",
      "\n",
      "Test Accuracy: 0.6550807605806583\n",
      "\n",
      "------------\n",
      "Replicate 4\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7041416027103644\n",
      "\n",
      "Train Loss: 5.120999406867098\n",
      "\n",
      "Test Accuracy: 0.6479247597628297\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7290672751158128\n",
      "\n",
      "Train Loss: 5.0374628089001785\n",
      "\n",
      "Test Accuracy: 0.6495604170926191\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7754960934799142\n",
      "\n",
      "Train Loss: 4.897016745790942\n",
      "\n",
      "Test Accuracy: 0.6671437333878553\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7911567447970684\n",
      "\n",
      "Train Loss: 4.8271054966396365\n",
      "\n",
      "Test Accuracy: 0.6679615620527499\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8074051026757934\n",
      "\n",
      "Train Loss: 4.750907344842741\n",
      "\n",
      "Test Accuracy: 0.6742997342056839\n",
      "\n",
      "------------\n",
      "Replicate 5\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7255064647721773\n",
      "\n",
      "Train Loss: 5.111430335936196\n",
      "\n",
      "Test Accuracy: 0.6514005315886322\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7579340385812072\n",
      "\n",
      "Train Loss: 4.946977560785175\n",
      "\n",
      "Test Accuracy: 0.6491515027601718\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7930235774044112\n",
      "\n",
      "Train Loss: 4.845346155655502\n",
      "\n",
      "Test Accuracy: 0.6706195052136578\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8101707806125976\n",
      "\n",
      "Train Loss: 4.759975280133883\n",
      "\n",
      "Test Accuracy: 0.6657125332242895\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8161169881767268\n",
      "\n",
      "Train Loss: 4.766974490315311\n",
      "\n",
      "Test Accuracy: 0.6824780208546309\n",
      "\n",
      "------------\n",
      "Replicate 6\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.6761736845744313\n",
      "\n",
      "Train Loss: 5.185787045163728\n",
      "\n",
      "Test Accuracy: 0.6381108157840932\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7576228998133168\n",
      "\n",
      "Train Loss: 4.9226427334871845\n",
      "\n",
      "Test Accuracy: 0.6522183602535269\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7847956855424186\n",
      "\n",
      "Train Loss: 4.866415189549359\n",
      "\n",
      "Test Accuracy: 0.6820691065221836\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8089262255410358\n",
      "\n",
      "Train Loss: 4.745742663338138\n",
      "\n",
      "Test Accuracy: 0.6679615620527499\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.796100394109106\n",
      "\n",
      "Train Loss: 4.781869411305643\n",
      "\n",
      "Test Accuracy: 0.6720507053772234\n",
      "\n",
      "------------\n",
      "Replicate 7\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7105372329392242\n",
      "\n",
      "Train Loss: 5.149933820537539\n",
      "\n",
      "Test Accuracy: 0.6096912696790022\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7170020051165041\n",
      "\n",
      "Train Loss: 5.027675522290673\n",
      "\n",
      "Test Accuracy: 0.6417910447761194\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7583834612459379\n",
      "\n",
      "Train Loss: 4.957226983931102\n",
      "\n",
      "Test Accuracy: 0.6561030464117767\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7759109451704349\n",
      "\n",
      "Train Loss: 4.901175090391233\n",
      "\n",
      "Test Accuracy: 0.6614189327335923\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7780543455714583\n",
      "\n",
      "Train Loss: 4.858398352916568\n",
      "\n",
      "Test Accuracy: 0.6663259047229605\n",
      "\n",
      "------------\n",
      "Replicate 8\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.677936804259144\n",
      "\n",
      "Train Loss: 5.18569926493641\n",
      "\n",
      "Test Accuracy: 0.6634635043958291\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7598008711885501\n",
      "\n",
      "Train Loss: 4.958888694245016\n",
      "\n",
      "Test Accuracy: 0.6520139030873032\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7459379105303188\n",
      "\n",
      "Train Loss: 4.9897416312857\n",
      "\n",
      "Test Accuracy: 0.6569208750766714\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8098596418447072\n",
      "\n",
      "Train Loss: 4.8045729335830565\n",
      "\n",
      "Test Accuracy: 0.6595788182375792\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7974832330775081\n",
      "\n",
      "Train Loss: 4.792532254685914\n",
      "\n",
      "Test Accuracy: 0.6606011040686977\n",
      "\n",
      "------------\n",
      "Replicate 9\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.6945308718799695\n",
      "\n",
      "Train Loss: 5.143683295386073\n",
      "\n",
      "Test Accuracy: 0.6056021263545287\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7460070524787389\n",
      "\n",
      "Train Loss: 4.996083438585634\n",
      "\n",
      "Test Accuracy: 0.6636679615620528\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7974486621032981\n",
      "\n",
      "Train Loss: 4.797615514752435\n",
      "\n",
      "Test Accuracy: 0.6655080760580658\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7604922906727511\n",
      "\n",
      "Train Loss: 4.913299245640781\n",
      "\n",
      "Test Accuracy: 0.6608055612349213\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7972412362580378\n",
      "\n",
      "Train Loss: 4.790562423414491\n",
      "\n",
      "Test Accuracy: 0.6677571048865263\n",
      "\n",
      "------------\n",
      "Replicate 10\n",
      "------------\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7209085252022402\n",
      "\n",
      "Train Loss: 5.075429119729289\n",
      "\n",
      "Test Accuracy: 0.6432222449396852\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7220147963769619\n",
      "\n",
      "Train Loss: 5.06007162724311\n",
      "\n",
      "Test Accuracy: 0.6432222449396852\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Accuracy: 0.7616331328216829\n",
      "\n",
      "Train Loss: 4.92387943975569\n",
      "\n",
      "Test Accuracy: 0.6405643017787773\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Accuracy: 0.795443545599115\n",
      "\n",
      "Train Loss: 4.831696130603494\n",
      "\n",
      "Test Accuracy: 0.6526272745859742\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train Accuracy: 0.8125561778330913\n",
      "\n",
      "Train Loss: 4.745404627472214\n",
      "\n",
      "Test Accuracy: 0.6620323042322633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"------------\\nReplicate {i+1}\\n------------\")\n",
    "    train_idx, test_idx, _, _ = train_test_split(np.arange(X.shape[0]), observed, test_size=0.3, random_state=i)\n",
    "\n",
    "    train_X = X[train_idx,:]\n",
    "    test_X = X[test_idx,:]\n",
    "\n",
    "    train_time = time[train_idx]\n",
    "    test_time = time[test_idx]\n",
    "\n",
    "    train_observed = observed[train_idx]\n",
    "    test_observed = observed[test_idx]\n",
    "    model = Coxnnet(train_X.shape[1], hidden_dim)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        model.train()\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, t)\n",
    "        model.eval()\n",
    "        test_loop(test_dataloader, model, t)\n",
    "        \n",
    "PAAD_acc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average of accuracy per data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of KIRC acc : 0.6537722347168268\n",
      "Average of LAML acc : 0.6590881210386424\n",
      "Average of PAAD acc : 0.6649355959926395\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average of KIRC acc : {sum(KIRC_acc)/len(KIRC_acc)}\")\n",
    "print(f\"Average of LAML acc : {sum(LAML_acc)/len(LAML_acc)}\")\n",
    "print(f\"Average of PAAD acc : {sum(PAAD_acc)/len(PAAD_acc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x960 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(8, 12), dpi=80)\n",
    "\n",
    "data = [KIRC_acc, LAML_acc, PAAD_acc]\n",
    "plt.boxplot(data, labels=['KIRC', 'LAML', 'PAAD'])\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('hek')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0491cbb347169b674faecc57483f555701d022daf991287b1e1cb5e40250a57a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
